apiVersion: v1
kind: Pod
metadata:
  annotations:
    openshift.io/scc: restricted-v2
    seccomp.security.alpha.kubernetes.io/pod: runtime/default
  creationTimestamp: "2023-03-08T11:52:57Z"
  generateName: ingress-canary-
  labels:
    controller-revision-hash: 8656f55ddb
    ingresscanary.operator.openshift.io/daemonset-ingresscanary: canary_controller
    pod-template-generation: "1"
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:target.workload.openshift.io/management: {}
        f:generateName: {}
        f:labels:
          .: {}
          f:controller-revision-hash: {}
          f:ingresscanary.operator.openshift.io/daemonset-ingresscanary: {}
          f:pod-template-generation: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"57849325-9a52-432b-9fe5-ba6afbae1635"}: {}
      f:spec:
        f:affinity:
          .: {}
          f:nodeAffinity:
            .: {}
            f:requiredDuringSchedulingIgnoredDuringExecution: {}
        f:containers:
          k:{"name":"serve-healthcheck-canary"}:
            .: {}
            f:command: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":8080,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:protocol: {}
              k:{"containerPort":8888,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:protocol: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:securityContext:
              .: {}
              f:allowPrivilegeEscalation: {}
              f:capabilities:
                .: {}
                f:drop: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
        f:dnsPolicy: {}
        f:enableServiceLinks: {}
        f:nodeSelector: {}
        f:priorityClassName: {}
        f:restartPolicy: {}
        f:schedulerName: {}
        f:securityContext:
          .: {}
          f:runAsNonRoot: {}
          f:seccompProfile:
            .: {}
            f:type: {}
        f:terminationGracePeriodSeconds: {}
        f:tolerations: {}
    manager: kube-controller-manager
    operation: Update
    time: "2023-03-08T11:52:57Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions:
          k:{"type":"ContainersReady"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:message: {}
            f:reason: {}
            f:status: {}
            f:type: {}
          k:{"type":"Initialized"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Ready"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:message: {}
            f:reason: {}
            f:status: {}
            f:type: {}
        f:containerStatuses: {}
        f:hostIP: {}
        f:startTime: {}
    manager: kubelet
    operation: Update
    subresource: status
    time: "2023-03-08T11:52:57Z"
  name: ingress-canary-ltw5l
  namespace: openshift-ingress-canary
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: DaemonSet
    name: ingress-canary
    uid: 57849325-9a52-432b-9fe5-ba6afbae1635
  resourceVersion: "20653"
  uid: e3e1f81c-152f-4000-a276-7bd28fed5a93
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchFields:
          - key: metadata.name
            operator: In
            values:
            - vrutkovs-mrmwt-worker-c-hztvh.c.openshift-gce-devel.internal
  containers:
  - command:
    - ingress-operator
    - serve-healthcheck
    image: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:b79ae5b794a95f814a3454c300ec678169285167f9f117d1465f7ad8f4cb4806
    imagePullPolicy: IfNotPresent
    name: serve-healthcheck-canary
    ports:
    - containerPort: 8080
      protocol: TCP
    - containerPort: 8888
      protocol: TCP
    resources:
      requests:
        cpu: 10m
        memory: 20Mi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      runAsUser: 1000630000
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-gjglw
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  imagePullSecrets:
  - name: default-dockercfg-5b729
  nodeName: vrutkovs-mrmwt-worker-c-hztvh.c.openshift-gce-devel.internal
  nodeSelector:
    kubernetes.io/os: linux
  preemptionPolicy: PreemptLowerPriority
  priority: 2000000000
  priorityClassName: system-cluster-critical
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext:
    fsGroup: 1000630000
    runAsNonRoot: true
    seLinuxOptions:
      level: s0:c25,c15
    seccompProfile:
      type: RuntimeDefault
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/infra
    operator: Exists
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/disk-pressure
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/memory-pressure
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/pid-pressure
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/unschedulable
    operator: Exists
  volumes:
  - name: kube-api-access-gjglw
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
      - configMap:
          items:
          - key: service-ca.crt
            path: service-ca.crt
          name: openshift-service-ca.crt
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2023-03-08T11:52:57Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2023-03-08T11:52:57Z"
    message: 'containers with unready status: [serve-healthcheck-canary]'
    reason: ContainersNotReady
    status: "False"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2023-03-08T11:52:57Z"
    message: 'containers with unready status: [serve-healthcheck-canary]'
    reason: ContainersNotReady
    status: "False"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2023-03-08T11:52:57Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - image: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:b79ae5b794a95f814a3454c300ec678169285167f9f117d1465f7ad8f4cb4806
    imageID: ""
    lastState: {}
    name: serve-healthcheck-canary
    ready: false
    restartCount: 0
    started: false
    state:
      waiting:
        reason: ContainerCreating
  hostIP: 10.0.128.4
  phase: Pending
  qosClass: Burstable
  startTime: "2023-03-08T11:52:57Z"
