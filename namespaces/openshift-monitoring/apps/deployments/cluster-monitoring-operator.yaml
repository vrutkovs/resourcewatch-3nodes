apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
  creationTimestamp: "2023-03-08T11:41:20Z"
  generation: 1
  labels:
    app: cluster-monitoring-operator
    app.kubernetes.io/name: cluster-monitoring-operator
  managedFields:
  - apiVersion: apps/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:include.release.openshift.io/self-managed-high-availability: {}
          f:include.release.openshift.io/single-node-developer: {}
        f:labels:
          .: {}
          f:app: {}
          f:app.kubernetes.io/name: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"e60de632-2954-4109-a630-deda141a29af"}: {}
      f:spec:
        f:progressDeadlineSeconds: {}
        f:replicas: {}
        f:revisionHistoryLimit: {}
        f:selector: {}
        f:strategy:
          f:rollingUpdate:
            .: {}
            f:maxSurge: {}
            f:maxUnavailable: {}
          f:type: {}
        f:template:
          f:metadata:
            f:annotations:
              .: {}
              f:target.workload.openshift.io/management: {}
            f:labels:
              .: {}
              f:app: {}
              f:app.kubernetes.io/name: {}
          f:spec:
            f:containers:
              k:{"name":"cluster-monitoring-operator"}:
                .: {}
                f:args: {}
                f:env:
                  .: {}
                  k:{"name":"RELEASE_VERSION"}:
                    .: {}
                    f:name: {}
                    f:value: {}
                f:image: {}
                f:imagePullPolicy: {}
                f:name: {}
                f:resources:
                  .: {}
                  f:requests:
                    .: {}
                    f:cpu: {}
                    f:memory: {}
                f:terminationMessagePath: {}
                f:terminationMessagePolicy: {}
                f:volumeMounts:
                  .: {}
                  k:{"mountPath":"/etc/cluster-monitoring-operator/telemetry"}:
                    .: {}
                    f:mountPath: {}
                    f:name: {}
              k:{"name":"kube-rbac-proxy"}:
                .: {}
                f:args: {}
                f:image: {}
                f:imagePullPolicy: {}
                f:name: {}
                f:ports:
                  .: {}
                  k:{"containerPort":8443,"protocol":"TCP"}:
                    .: {}
                    f:containerPort: {}
                    f:name: {}
                    f:protocol: {}
                f:resources:
                  .: {}
                  f:requests:
                    .: {}
                    f:cpu: {}
                    f:memory: {}
                f:terminationMessagePath: {}
                f:terminationMessagePolicy: {}
                f:volumeMounts:
                  .: {}
                  k:{"mountPath":"/etc/tls/private"}:
                    .: {}
                    f:mountPath: {}
                    f:name: {}
            f:dnsPolicy: {}
            f:nodeSelector: {}
            f:priorityClassName: {}
            f:restartPolicy: {}
            f:schedulerName: {}
            f:securityContext: {}
            f:serviceAccount: {}
            f:serviceAccountName: {}
            f:terminationGracePeriodSeconds: {}
            f:tolerations: {}
            f:volumes:
              .: {}
              k:{"name":"cluster-monitoring-operator-tls"}:
                .: {}
                f:name: {}
                f:secret:
                  .: {}
                  f:defaultMode: {}
                  f:secretName: {}
              k:{"name":"telemetry-config"}:
                .: {}
                f:configMap:
                  .: {}
                  f:defaultMode: {}
                  f:name: {}
                f:name: {}
    manager: cluster-version-operator
    operation: Update
    time: "2023-03-08T11:41:20Z"
  - apiVersion: apps/v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          f:deployment.kubernetes.io/revision: {}
      f:status:
        f:conditions:
          .: {}
          k:{"type":"Available"}:
            .: {}
            f:lastTransitionTime: {}
            f:lastUpdateTime: {}
            f:message: {}
            f:reason: {}
            f:status: {}
            f:type: {}
          k:{"type":"Progressing"}:
            .: {}
            f:lastTransitionTime: {}
            f:lastUpdateTime: {}
            f:message: {}
            f:reason: {}
            f:status: {}
            f:type: {}
        f:observedGeneration: {}
        f:replicas: {}
        f:unavailableReplicas: {}
        f:updatedReplicas: {}
    manager: kube-controller-manager
    operation: Update
    subresource: status
    time: "2023-03-08T11:54:20Z"
  name: cluster-monitoring-operator
  namespace: openshift-monitoring
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    kind: ClusterVersion
    name: version
    uid: e60de632-2954-4109-a630-deda141a29af
  resourceVersion: "21609"
  uid: 2d025294-a61e-4ee1-87b9-879d68e083ef
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: cluster-monitoring-operator
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
        target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
      creationTimestamp: null
      labels:
        app: cluster-monitoring-operator
        app.kubernetes.io/name: cluster-monitoring-operator
    spec:
      containers:
      - args:
        - --logtostderr
        - --secure-listen-address=:8443
        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
        - --upstream=http://127.0.0.1:8080/
        - --tls-cert-file=/etc/tls/private/tls.crt
        - --tls-private-key-file=/etc/tls/private/tls.key
        image: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:ff07afaff7fff38e3124162c5791ba969bcd750be02d5878f0387aed62517fa9
        imagePullPolicy: IfNotPresent
        name: kube-rbac-proxy
        ports:
        - containerPort: 8443
          name: https
          protocol: TCP
        resources:
          requests:
            cpu: 1m
            memory: 20Mi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /etc/tls/private
          name: cluster-monitoring-operator-tls
      - args:
        - -namespace=openshift-monitoring
        - -namespace-user-workload=openshift-user-workload-monitoring
        - -configmap=cluster-monitoring-config
        - -release-version=$(RELEASE_VERSION)
        - -logtostderr=true
        - -v=2
        - -images=prometheus-operator=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:b3a2976d75c99a95cab1e76bbebfcdf61c182b9ec08478e73efec20f3072f218
        - -images=prometheus-config-reloader=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:0f7088516f2eeba84a8fdbed70658a4b5958247051bc9cb489667864ed74fc08
        - -images=prometheus-operator-admission-webhook=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:a411d78abd27ec5224a7cbe4c0c93419789d29b612cf404fdd58839de1e14121
        - -images=configmap-reloader=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:5a4acb3564a29282063b6f91e0df3cbc022c0fb1ca8b6c1db64411683d4b43e6
        - -images=prometheus=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:91e7d68b28aa00e209065604b2b9ac1400671d9102581e8b49b37726acd7b6e4
        - -images=alertmanager=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:e6173b5d77def9e8058c7ff82f1ad65f537d1a81f88fcdabe6d8e30bff49ca89
        - -images=oauth-proxy=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:b6536bfcfaf30a6425d589facd672bae3245f933b2a7399bda3f12e393bd671b
        - -images=node-exporter=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:c4218978f242fbc800301ede5f4a53c0520dbcccc0b65d88c653731aa2781180
        - -images=kube-state-metrics=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:e5521a3d1f64483e63ffe5bc23d9f882781cd4d152ac6de72013eaefe6dfcf89
        - -images=openshift-state-metrics=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:685911b0e1df40d338acfb04340ad8b5033930033644cbd784c8c45cce5bd614
        - -images=kube-rbac-proxy=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:ff07afaff7fff38e3124162c5791ba969bcd750be02d5878f0387aed62517fa9
        - -images=telemeter-client=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:8228bf171cca1bc554576a310ad7bd3070f538e7b37ded86c7d28cd8b9cb0527
        - -images=prom-label-proxy=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:63a03be7e8759270b4a2c75112207867ef51774db5f682d4d2f711d0934fc816
        - -images=k8s-prometheus-adapter=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:9696f8f231d49aadf63ab980ec5c17c4fd87011930daecd30cc9e4ee102f1aeb
        - -images=thanos=registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:a5ebc0877eeb833483b35b36de0bccc2256a7b6eedc06c1e57f7b0ccd8c47bf7
        env:
        - name: RELEASE_VERSION
          value: 4.12.0-0.okd-2023-03-04-063026
        image: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:fe816127f712182bd8e4727df265e9b616f0139446110182927cd4c194f38fbe
        imagePullPolicy: IfNotPresent
        name: cluster-monitoring-operator
        resources:
          requests:
            cpu: 10m
            memory: 75Mi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /etc/cluster-monitoring-operator/telemetry
          name: telemetry-config
      dnsPolicy: ClusterFirst
      nodeSelector:
        kubernetes.io/os: linux
        node-role.kubernetes.io/master: ""
      priorityClassName: system-cluster-critical
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: cluster-monitoring-operator
      serviceAccountName: cluster-monitoring-operator
      terminationGracePeriodSeconds: 30
      tolerations:
      - effect: NoSchedule
        key: node.kubernetes.io/memory-pressure
        operator: Exists
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
        operator: Exists
      - effect: NoExecute
        key: node.kubernetes.io/unreachable
        operator: Exists
        tolerationSeconds: 120
      - effect: NoExecute
        key: node.kubernetes.io/not-ready
        operator: Exists
        tolerationSeconds: 120
      volumes:
      - configMap:
          defaultMode: 420
          name: telemetry-config
        name: telemetry-config
      - name: cluster-monitoring-operator-tls
        secret:
          defaultMode: 420
          secretName: cluster-monitoring-operator-tls
status:
  conditions:
  - lastTransitionTime: "2023-03-08T11:41:20Z"
    lastUpdateTime: "2023-03-08T11:46:21Z"
    message: ReplicaSet "cluster-monitoring-operator-866b465b44" has successfully
      progressed.
    reason: NewReplicaSetAvailable
    status: "True"
    type: Progressing
  - lastTransitionTime: "2023-03-08T11:54:20Z"
    lastUpdateTime: "2023-03-08T11:54:20Z"
    message: Deployment does not have minimum availability.
    reason: MinimumReplicasUnavailable
    status: "False"
    type: Available
  observedGeneration: 1
  replicas: 1
  unavailableReplicas: 1
  updatedReplicas: 1
