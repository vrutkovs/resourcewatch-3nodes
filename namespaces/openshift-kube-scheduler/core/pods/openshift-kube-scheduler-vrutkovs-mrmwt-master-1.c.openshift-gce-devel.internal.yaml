apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubectl.kubernetes.io/default-container: kube-scheduler
    kubernetes.io/config.hash: bb43da128b15fbe7e319976e647aae5f
    kubernetes.io/config.mirror: bb43da128b15fbe7e319976e647aae5f
    kubernetes.io/config.seen: "2023-03-08T11:48:11.614279439Z"
    kubernetes.io/config.source: file
    target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
  creationTimestamp: "2023-03-08T11:48:26Z"
  labels:
    app: openshift-kube-scheduler
    revision: "5"
    scheduler: "true"
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:kubectl.kubernetes.io/default-container: {}
          f:kubernetes.io/config.hash: {}
          f:kubernetes.io/config.mirror: {}
          f:kubernetes.io/config.seen: {}
          f:kubernetes.io/config.source: {}
          f:target.workload.openshift.io/management: {}
        f:labels:
          .: {}
          f:app: {}
          f:revision: {}
          f:scheduler: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"d1bb260b-ed05-4c1f-9090-1cf4ac4bb308"}: {}
      f:spec:
        f:containers:
          k:{"name":"kube-scheduler"}:
            .: {}
            f:args: {}
            f:command: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:livenessProbe:
              .: {}
              f:failureThreshold: {}
              f:httpGet:
                .: {}
                f:path: {}
                f:port: {}
                f:scheme: {}
              f:initialDelaySeconds: {}
              f:periodSeconds: {}
              f:successThreshold: {}
              f:timeoutSeconds: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":10259,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:protocol: {}
            f:readinessProbe:
              .: {}
              f:failureThreshold: {}
              f:httpGet:
                .: {}
                f:path: {}
                f:port: {}
                f:scheme: {}
              f:initialDelaySeconds: {}
              f:periodSeconds: {}
              f:successThreshold: {}
              f:timeoutSeconds: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/kubernetes/static-pod-certs"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/kubernetes/static-pod-resources"}:
                .: {}
                f:mountPath: {}
                f:name: {}
          k:{"name":"kube-scheduler-cert-syncer"}:
            .: {}
            f:args: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"POD_NAME"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
              k:{"name":"POD_NAMESPACE"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/kubernetes/static-pod-certs"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/kubernetes/static-pod-resources"}:
                .: {}
                f:mountPath: {}
                f:name: {}
          k:{"name":"kube-scheduler-recovery-controller"}:
            .: {}
            f:args: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"POD_NAMESPACE"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/kubernetes/static-pod-certs"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/kubernetes/static-pod-resources"}:
                .: {}
                f:mountPath: {}
                f:name: {}
        f:dnsPolicy: {}
        f:enableServiceLinks: {}
        f:hostNetwork: {}
        f:initContainers:
          .: {}
          k:{"name":"wait-for-host-port"}:
            .: {}
            f:args: {}
            f:command: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
        f:nodeName: {}
        f:priorityClassName: {}
        f:restartPolicy: {}
        f:schedulerName: {}
        f:securityContext: {}
        f:terminationGracePeriodSeconds: {}
        f:tolerations: {}
        f:volumes:
          .: {}
          k:{"name":"cert-dir"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
          k:{"name":"resource-dir"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
    manager: kubelet
    operation: Update
    time: "2023-03-08T11:48:26Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions:
          .: {}
          k:{"type":"ContainersReady"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Initialized"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"PodScheduled"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Ready"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
        f:containerStatuses: {}
        f:hostIP: {}
        f:initContainerStatuses: {}
        f:phase: {}
        f:podIP: {}
        f:podIPs:
          .: {}
          k:{"ip":"10.0.0.4"}:
            .: {}
            f:ip: {}
        f:startTime: {}
    manager: kubelet
    operation: Update
    subresource: status
    time: "2023-03-08T11:55:56Z"
  name: openshift-kube-scheduler-vrutkovs-mrmwt-master-1.c.openshift-gce-devel.internal
  namespace: openshift-kube-scheduler
  ownerReferences:
  - apiVersion: v1
    controller: true
    kind: Node
    name: vrutkovs-mrmwt-master-1.c.openshift-gce-devel.internal
    uid: d1bb260b-ed05-4c1f-9090-1cf4ac4bb308
  resourceVersion: "23186"
  uid: 24a959c4-ec13-4541-b9a2-907e898bd4ce
spec:
  containers:
  - args:
    - --config=/etc/kubernetes/static-pod-resources/configmaps/config/config.yaml
    - --cert-dir=/var/run/kubernetes
    - --authentication-kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/scheduler-kubeconfig/kubeconfig
    - --authorization-kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/scheduler-kubeconfig/kubeconfig
    - --feature-gates=APIPriorityAndFairness=true,CSIMigrationAzureFile=false,CSIMigrationvSphere=false,DownwardAPIHugePages=true,RotateKubeletServerCertificate=true
    - -v=2
    - --tls-cert-file=/etc/kubernetes/static-pod-resources/secrets/serving-cert/tls.crt
    - --tls-private-key-file=/etc/kubernetes/static-pod-resources/secrets/serving-cert/tls.key
    - --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
    - --tls-min-version=VersionTLS12
    command:
    - hyperkube
    - kube-scheduler
    image: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:101b679b179be4e937b7770a01d3ca316586b97f61cc4e02f2a0d502cc60c3f0
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 3
      httpGet:
        path: healthz
        port: 10259
        scheme: HTTPS
      initialDelaySeconds: 45
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    name: kube-scheduler
    ports:
    - containerPort: 10259
      hostPort: 10259
      protocol: TCP
    readinessProbe:
      failureThreshold: 3
      httpGet:
        path: healthz
        port: 10259
        scheme: HTTPS
      initialDelaySeconds: 45
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    resources:
      requests:
        cpu: 15m
        memory: 50Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/kubernetes/static-pod-resources
      name: resource-dir
    - mountPath: /etc/kubernetes/static-pod-certs
      name: cert-dir
  - args:
    - --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-scheduler-cert-syncer-kubeconfig/kubeconfig
    - --namespace=$(POD_NAMESPACE)
    - --destination-dir=/etc/kubernetes/static-pod-certs
    command:
    - cluster-kube-scheduler-operator
    - cert-syncer
    env:
    - name: POD_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.namespace
    image: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:10cd65f1fa350f59f47e0516be74acd81a6f9b1afe596f7b46af67e1f5688322
    imagePullPolicy: IfNotPresent
    name: kube-scheduler-cert-syncer
    resources:
      requests:
        cpu: 5m
        memory: 50Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/kubernetes/static-pod-resources
      name: resource-dir
    - mountPath: /etc/kubernetes/static-pod-certs
      name: cert-dir
  - args:
    - |
      timeout 3m /bin/bash -exuo pipefail -c 'while [ -n "$(ss -Htanop \( sport = 11443 \))" ]; do sleep 1; done'

      exec cluster-kube-scheduler-operator cert-recovery-controller --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-scheduler-cert-syncer-kubeconfig/kubeconfig  --namespace=${POD_NAMESPACE} --listen=0.0.0.0:11443 -v=2
    command:
    - /bin/bash
    - -euxo
    - pipefail
    - -c
    env:
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.namespace
    image: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:10cd65f1fa350f59f47e0516be74acd81a6f9b1afe596f7b46af67e1f5688322
    imagePullPolicy: IfNotPresent
    name: kube-scheduler-recovery-controller
    resources:
      requests:
        cpu: 5m
        memory: 50Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/kubernetes/static-pod-resources
      name: resource-dir
    - mountPath: /etc/kubernetes/static-pod-certs
      name: cert-dir
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  hostNetwork: true
  initContainers:
  - args:
    - |
      echo -n "Waiting for port :10259 to be released."
      while [ -n "$(ss -Htan '( sport = 10259 )')" ]; do
        echo -n "."
        sleep 1
      done
    command:
    - /usr/bin/timeout
    - "30"
    - /bin/bash
    - -c
    image: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:101b679b179be4e937b7770a01d3ca316586b97f61cc4e02f2a0d502cc60c3f0
    imagePullPolicy: IfNotPresent
    name: wait-for-host-port
    resources:
      requests:
        cpu: 15m
        memory: 50Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
  nodeName: vrutkovs-mrmwt-master-1.c.openshift-gce-devel.internal
  preemptionPolicy: PreemptLowerPriority
  priority: 2000001000
  priorityClassName: system-node-critical
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  terminationGracePeriodSeconds: 30
  tolerations:
  - operator: Exists
  volumes:
  - hostPath:
      path: /etc/kubernetes/static-pod-resources/kube-scheduler-pod-5
      type: ""
    name: resource-dir
  - hostPath:
      path: /etc/kubernetes/static-pod-resources/kube-scheduler-certs
      type: ""
    name: cert-dir
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2023-03-08T11:48:26Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2023-03-08T11:55:56Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2023-03-08T11:55:56Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2023-03-08T11:46:24Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: cri-o://3dc523ff4cf76fd065e2354c17beb5bae0de33b6b9af52e412e605c790165ed6
    image: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:101b679b179be4e937b7770a01d3ca316586b97f61cc4e02f2a0d502cc60c3f0
    imageID: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:101b679b179be4e937b7770a01d3ca316586b97f61cc4e02f2a0d502cc60c3f0
    lastState:
      terminated:
        containerID: cri-o://3848e8bfccc97af8e53bc73171bf628f4763f2cb247225182a986f9221c06e74
        exitCode: 1
        finishedAt: "2023-03-08T11:55:04Z"
        message: |
          8 11:54:56.060609       1 schedule_one.go:885] "Error updating pod" err="Timeout: request did not complete within requested timeout - context deadline exceeded" pod="openshift-apiserver/apiserver-f6774f75f-42d5r"
          I0308 11:54:56.082838       1 schedule_one.go:266] "Successfully bound pod to node" pod="openshift-image-registry/image-registry-7ccd686b74-sxb9k" node="vrutkovs-mrmwt-worker-b-5rcfz.c.openshift-gce-devel.internal" evaluatedNodes=6 feasibleNodes=2
          I0308 11:54:56.086472       1 schedule_one.go:266] "Successfully bound pod to node" pod="openshift-image-registry/image-registry-7dc9976b6f-8fcjs" node="vrutkovs-mrmwt-worker-a-92xck.c.openshift-gce-devel.internal" evaluatedNodes=6 feasibleNodes=1
          I0308 11:55:01.070518       1 schedule_one.go:266] "Successfully bound pod to node" pod="openshift-oauth-apiserver/apiserver-86c9ff68c6-m7x6s" node="vrutkovs-mrmwt-master-2.c.openshift-gce-devel.internal" evaluatedNodes=6 feasibleNodes=1
          I0308 11:55:02.575237       1 schedule_one.go:826] "Unable to schedule pod; no fit; waiting" pod="openshift-apiserver/apiserver-f6774f75f-42d5r" err="0/6 nodes are available: 3 node(s) didn't match Pod's node affinity/selector, 3 node(s) didn't match pod anti-affinity rules, 3 node(s) had untolerated taint {node.kubernetes.io/unreachable: }. preemption: 0/6 nodes are available: 3 Preemption is not helpful for scheduling, 3 node(s) didn't match pod anti-affinity rules."
          E0308 11:55:04.499065       1 leaderelection.go:330] error retrieving resource lock openshift-kube-scheduler/kube-scheduler: Get "https://api-int.vrutkovs.origin-gce.dev.openshift.com:6443/api/v1/namespaces/openshift-kube-scheduler/configmaps/kube-scheduler?timeout=53.5s": context deadline exceeded
          I0308 11:55:04.499116       1 leaderelection.go:283] failed to renew lease openshift-kube-scheduler/kube-scheduler: timed out waiting for the condition
          E0308 11:55:04.499165       1 leaderelection.go:306] Failed to release lock: resource name may not be empty
          E0308 11:55:04.499179       1 server.go:229] "Leaderelection lost"
        reason: Error
        startedAt: "2023-03-08T11:48:26Z"
    name: kube-scheduler
    ready: true
    restartCount: 1
    started: true
    state:
      running:
        startedAt: "2023-03-08T11:55:05Z"
  - containerID: cri-o://e2e2c762e88eb84a7b19e9dfd32e8f1a91091bd3015b1673d668a3be774b644d
    image: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:10cd65f1fa350f59f47e0516be74acd81a6f9b1afe596f7b46af67e1f5688322
    imageID: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:10cd65f1fa350f59f47e0516be74acd81a6f9b1afe596f7b46af67e1f5688322
    lastState: {}
    name: kube-scheduler-cert-syncer
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2023-03-08T11:48:27Z"
  - containerID: cri-o://ff9c5dfdfe626378b46cdb1f735438e4f7acc1e14f022ba400fabb56a51c7674
    image: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:10cd65f1fa350f59f47e0516be74acd81a6f9b1afe596f7b46af67e1f5688322
    imageID: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:10cd65f1fa350f59f47e0516be74acd81a6f9b1afe596f7b46af67e1f5688322
    lastState: {}
    name: kube-scheduler-recovery-controller
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2023-03-08T11:48:27Z"
  hostIP: 10.0.0.4
  initContainerStatuses:
  - containerID: cri-o://2d6894316dfcffbfde5272abbbf33fdd6a0d4449bf55bbe79147bbef73db7bbc
    image: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:101b679b179be4e937b7770a01d3ca316586b97f61cc4e02f2a0d502cc60c3f0
    imageID: registry.ci.openshift.org/origin/4.12-2023-03-04-063026@sha256:101b679b179be4e937b7770a01d3ca316586b97f61cc4e02f2a0d502cc60c3f0
    lastState: {}
    name: wait-for-host-port
    ready: true
    restartCount: 0
    state:
      terminated:
        containerID: cri-o://2d6894316dfcffbfde5272abbbf33fdd6a0d4449bf55bbe79147bbef73db7bbc
        exitCode: 0
        finishedAt: "2023-03-08T11:48:26Z"
        reason: Completed
        startedAt: "2023-03-08T11:48:26Z"
  phase: Running
  podIP: 10.0.0.4
  podIPs:
  - ip: 10.0.0.4
  qosClass: Burstable
  startTime: "2023-03-08T11:46:24Z"
